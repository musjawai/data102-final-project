{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question\n",
    "Can we predict game outcomes using all past seasons' team statistics?\n",
    "For instance, if teams A and B are playing, can we use all the past seasons' statistics for team A and B to predict who will win?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['teams', 'players', 'games', 'ranking', 'games_details']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading each dataset into a dictionary\n",
    "datasets = {}\n",
    "for file_name in os.listdir('archive'):\n",
    "    if file_name.endswith('.csv'):\n",
    "        datasets[file_name.split('.')[0]] = pd.read_csv('archive/' + file_name, low_memory=False)\n",
    "\n",
    "list(datasets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning and Organizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping the team id, abbreviation, nickname, city, and arena capacity for each team in the teams dataset\n",
    "# replacing NaN and 0 values with the mean\n",
    "datasets['teams'] = datasets['teams'][['TEAM_ID', 'ABBREVIATION', 'NICKNAME', 'CITY', 'ARENACAPACITY']].fillna(0).replace(0, datasets['teams'][\"ARENACAPACITY\"].mean().round(0))\n",
    "\n",
    "datasets['game_details'] = datasets['games_details'][[\"GAME_ID\", \"TEAM_ID\", \"MIN\", \"FG_PCT\", \"FG3_PCT\", \"FT_PCT\", \n",
    "                                                    \"OREB\", \"DREB\", \"REB\", \"AST\", \"STL\", \"BLK\", \"TO\", \"PF\", \"PTS\", \"PLUS_MINUS\"]].dropna()\n",
    "datasets['game_details']['MIN'] = datasets['game_details']['MIN'].str.split(':').apply(lambda x: float(x[0]) + float(x[1])/60).round(3)\n",
    "\n",
    "datasets['ranking'] = datasets['ranking'][[\"TEAM_ID\", \"SEASON_ID\", \"STANDINGSDATE\", \"CONFERENCE\", \"G\", \"W_PCT\"]]\n",
    "datasets['ranking'][\"STANDINGSDATE\"] = pd.to_datetime(datasets['ranking'][\"STANDINGSDATE\"])\n",
    "\n",
    "datasets['games'] = datasets['games'].drop(['GAME_STATUS_TEXT', \"TEAM_ID_home\", \"TEAM_ID_away\"], axis=1)\n",
    "datasets['games'][\"GAME_DATE_EST\"] = pd.to_datetime(datasets['games'][\"GAME_DATE_EST\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating the win percentages by team on that date\n",
    "# first joining for the home team\n",
    "datasets['games'] = datasets['games'].merge(datasets['ranking'], left_on=['HOME_TEAM_ID', 'GAME_DATE_EST'], right_on=['TEAM_ID', 'STANDINGSDATE'], how='left', suffixes=('', '_home_ranking')).rename(columns={'W_PCT': 'HOME_TEAM_W_PCT', 'CONFERENCE': 'HOME_TEAM_CONFERENCE'}).drop(['TEAM_ID', 'STANDINGSDATE', 'G'], axis=1)\n",
    "# now we do the same for the away team\n",
    "datasets['games'] = datasets['games'].merge(datasets['ranking'], left_on=['VISITOR_TEAM_ID', 'GAME_DATE_EST'], right_on=['TEAM_ID', 'STANDINGSDATE'], how='left', suffixes=('', '_away_ranking')).rename(columns={'W_PCT': 'VISITOR_TEAM_W_PCT', 'CONFERENCE': 'VISITOR_TEAM_CONFERENCE'}).drop(['TEAM_ID', 'STANDINGSDATE', 'G', 'SEASON_ID_away_ranking', 'SEASON_ID'], axis=1)\n",
    "\n",
    "#fixing datatypes\n",
    "datasets['games']['SEASON'] = datasets['games']['SEASON'].astype('str')\n",
    "\n",
    "# nan values only for numerical variables, so we can fill them in with average\n",
    "datasets['games'].fillna(datasets['games'].select_dtypes(include=['float64', 'int64']).mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON</th>\n",
       "      <th>PTS_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>FG3_PCT_home</th>\n",
       "      <th>AST_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>PTS_away</th>\n",
       "      <th>FG_PCT_away</th>\n",
       "      <th>FT_PCT_away</th>\n",
       "      <th>FG3_PCT_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>REB_away</th>\n",
       "      <th>HOME_TEAM_WINS</th>\n",
       "      <th>HOME_TEAM_CONFERENCE</th>\n",
       "      <th>HOME_TEAM_W_PCT</th>\n",
       "      <th>VISITOR_TEAM_CONFERENCE</th>\n",
       "      <th>VISITOR_TEAM_W_PCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.382</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.321</td>\n",
       "      <td>23.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>West</td>\n",
       "      <td>0.613</td>\n",
       "      <td>West</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.457</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>West</td>\n",
       "      <td>0.543</td>\n",
       "      <td>East</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.313</td>\n",
       "      <td>22.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.433</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>East</td>\n",
       "      <td>0.667</td>\n",
       "      <td>East</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.297</td>\n",
       "      <td>27.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.261</td>\n",
       "      <td>15.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>East</td>\n",
       "      <td>0.600</td>\n",
       "      <td>East</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.378</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.292</td>\n",
       "      <td>20.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>East</td>\n",
       "      <td>0.500</td>\n",
       "      <td>East</td>\n",
       "      <td>0.419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SEASON  PTS_home  FG_PCT_home  FT_PCT_home  FG3_PCT_home  AST_home  \\\n",
       "0   2022     126.0        0.484        0.926         0.382      25.0   \n",
       "1   2022     120.0        0.488        0.952         0.457      16.0   \n",
       "2   2022     114.0        0.482        0.786         0.313      22.0   \n",
       "3   2022     113.0        0.441        0.909         0.297      27.0   \n",
       "4   2022     108.0        0.429        1.000         0.378      22.0   \n",
       "\n",
       "   REB_home  PTS_away  FG_PCT_away  FT_PCT_away  FG3_PCT_away  AST_away  \\\n",
       "0      46.0     117.0        0.478        0.815         0.321      23.0   \n",
       "1      40.0     112.0        0.561        0.765         0.333      20.0   \n",
       "2      37.0     106.0        0.470        0.682         0.433      20.0   \n",
       "3      49.0      93.0        0.392        0.735         0.261      15.0   \n",
       "4      47.0     110.0        0.500        0.773         0.292      20.0   \n",
       "\n",
       "   REB_away  HOME_TEAM_WINS HOME_TEAM_CONFERENCE  HOME_TEAM_W_PCT  \\\n",
       "0      44.0               1                 West            0.613   \n",
       "1      37.0               1                 West            0.543   \n",
       "2      46.0               1                 East            0.667   \n",
       "3      46.0               1                 East            0.600   \n",
       "4      47.0               0                 East            0.500   \n",
       "\n",
       "  VISITOR_TEAM_CONFERENCE  VISITOR_TEAM_W_PCT  \n",
       "0                    West               0.323  \n",
       "1                    East               0.364  \n",
       "2                    East               0.710  \n",
       "3                    East               0.235  \n",
       "4                    East               0.419  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have compiled a comprehensive dataset that we can do feature engineering on to make our models\n",
    "# taking out the identifiers: game_id, home_id, visitor_team_id and copying the dataset\n",
    "df = datasets['games'].copy().drop(['GAME_ID', 'HOME_TEAM_ID', 'VISITOR_TEAM_ID', 'GAME_DATE_EST'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTS_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>FG3_PCT_home</th>\n",
       "      <th>AST_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>PTS_away</th>\n",
       "      <th>FG_PCT_away</th>\n",
       "      <th>FT_PCT_away</th>\n",
       "      <th>FG3_PCT_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>REB_away</th>\n",
       "      <th>HOME_TEAM_W_PCT</th>\n",
       "      <th>VISITOR_TEAM_W_PCT</th>\n",
       "      <th>SEASON_2003</th>\n",
       "      <th>SEASON_2004</th>\n",
       "      <th>SEASON_2005</th>\n",
       "      <th>SEASON_2006</th>\n",
       "      <th>SEASON_2007</th>\n",
       "      <th>SEASON_2008</th>\n",
       "      <th>SEASON_2009</th>\n",
       "      <th>SEASON_2010</th>\n",
       "      <th>SEASON_2011</th>\n",
       "      <th>SEASON_2012</th>\n",
       "      <th>SEASON_2013</th>\n",
       "      <th>SEASON_2014</th>\n",
       "      <th>SEASON_2015</th>\n",
       "      <th>SEASON_2016</th>\n",
       "      <th>SEASON_2017</th>\n",
       "      <th>SEASON_2018</th>\n",
       "      <th>SEASON_2019</th>\n",
       "      <th>SEASON_2020</th>\n",
       "      <th>SEASON_2021</th>\n",
       "      <th>SEASON_2022</th>\n",
       "      <th>HOME_TEAM_CONFERENCE_East</th>\n",
       "      <th>HOME_TEAM_CONFERENCE_West</th>\n",
       "      <th>VISITOR_TEAM_CONFERENCE_East</th>\n",
       "      <th>VISITOR_TEAM_CONFERENCE_West</th>\n",
       "      <th>HOME_TEAM_WINS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.699190</td>\n",
       "      <td>0.410891</td>\n",
       "      <td>1.648311</td>\n",
       "      <td>0.233954</td>\n",
       "      <td>0.419333</td>\n",
       "      <td>0.396775</td>\n",
       "      <td>1.218498</td>\n",
       "      <td>0.509733</td>\n",
       "      <td>0.544237</td>\n",
       "      <td>-0.260829</td>\n",
       "      <td>0.291614</td>\n",
       "      <td>0.289059</td>\n",
       "      <td>0.514020</td>\n",
       "      <td>-0.904342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.246794</td>\n",
       "      <td>0.481598</td>\n",
       "      <td>1.907018</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>-1.316714</td>\n",
       "      <td>-0.510380</td>\n",
       "      <td>0.845829</td>\n",
       "      <td>2.006860</td>\n",
       "      <td>0.059811</td>\n",
       "      <td>-0.150969</td>\n",
       "      <td>-0.290883</td>\n",
       "      <td>-0.784524</td>\n",
       "      <td>0.160757</td>\n",
       "      <td>-0.697327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794397</td>\n",
       "      <td>0.375537</td>\n",
       "      <td>0.255273</td>\n",
       "      <td>-0.387870</td>\n",
       "      <td>-0.159349</td>\n",
       "      <td>-0.963957</td>\n",
       "      <td>0.398626</td>\n",
       "      <td>0.365432</td>\n",
       "      <td>-0.744336</td>\n",
       "      <td>0.764533</td>\n",
       "      <td>-0.290883</td>\n",
       "      <td>0.595796</td>\n",
       "      <td>0.786538</td>\n",
       "      <td>1.049680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.718998</td>\n",
       "      <td>-0.349213</td>\n",
       "      <td>1.479156</td>\n",
       "      <td>-0.532062</td>\n",
       "      <td>0.805122</td>\n",
       "      <td>0.850352</td>\n",
       "      <td>-0.570313</td>\n",
       "      <td>-1.041506</td>\n",
       "      <td>-0.230844</td>\n",
       "      <td>-0.810130</td>\n",
       "      <td>-1.261712</td>\n",
       "      <td>0.595796</td>\n",
       "      <td>0.448414</td>\n",
       "      <td>-1.348668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.342001</td>\n",
       "      <td>-0.561336</td>\n",
       "      <td>2.384631</td>\n",
       "      <td>0.197907</td>\n",
       "      <td>-0.159349</td>\n",
       "      <td>0.547967</td>\n",
       "      <td>0.696761</td>\n",
       "      <td>0.906562</td>\n",
       "      <td>0.137319</td>\n",
       "      <td>-0.526325</td>\n",
       "      <td>-0.290883</td>\n",
       "      <td>0.749165</td>\n",
       "      <td>-0.056248</td>\n",
       "      <td>-0.419624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PTS_home  FG_PCT_home  FT_PCT_home  FG3_PCT_home  AST_home  REB_home  \\\n",
       "0  1.699190     0.410891     1.648311      0.233954  0.419333  0.396775   \n",
       "1  1.246794     0.481598     1.907018      0.909851 -1.316714 -0.510380   \n",
       "2  0.794397     0.375537     0.255273     -0.387870 -0.159349 -0.963957   \n",
       "3  0.718998    -0.349213     1.479156     -0.532062  0.805122  0.850352   \n",
       "4  0.342001    -0.561336     2.384631      0.197907 -0.159349  0.547967   \n",
       "\n",
       "   PTS_away  FG_PCT_away  FT_PCT_away  FG3_PCT_away  AST_away  REB_away  \\\n",
       "0  1.218498     0.509733     0.544237     -0.260829  0.291614  0.289059   \n",
       "1  0.845829     2.006860     0.059811     -0.150969 -0.290883 -0.784524   \n",
       "2  0.398626     0.365432    -0.744336      0.764533 -0.290883  0.595796   \n",
       "3 -0.570313    -1.041506    -0.230844     -0.810130 -1.261712  0.595796   \n",
       "4  0.696761     0.906562     0.137319     -0.526325 -0.290883  0.749165   \n",
       "\n",
       "   HOME_TEAM_W_PCT  VISITOR_TEAM_W_PCT  SEASON_2003  SEASON_2004  SEASON_2005  \\\n",
       "0         0.514020           -0.904342          0.0          0.0          0.0   \n",
       "1         0.160757           -0.697327          0.0          0.0          0.0   \n",
       "2         0.786538            1.049680          0.0          0.0          0.0   \n",
       "3         0.448414           -1.348668          0.0          0.0          0.0   \n",
       "4        -0.056248           -0.419624          0.0          0.0          0.0   \n",
       "\n",
       "   SEASON_2006  SEASON_2007  SEASON_2008  SEASON_2009  SEASON_2010  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   SEASON_2011  SEASON_2012  SEASON_2013  SEASON_2014  SEASON_2015  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   SEASON_2016  SEASON_2017  SEASON_2018  SEASON_2019  SEASON_2020  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   SEASON_2021  SEASON_2022  HOME_TEAM_CONFERENCE_East  \\\n",
       "0          0.0          1.0                        0.0   \n",
       "1          0.0          1.0                        0.0   \n",
       "2          0.0          1.0                        1.0   \n",
       "3          0.0          1.0                        1.0   \n",
       "4          0.0          1.0                        1.0   \n",
       "\n",
       "   HOME_TEAM_CONFERENCE_West  VISITOR_TEAM_CONFERENCE_East  \\\n",
       "0                        1.0                           0.0   \n",
       "1                        1.0                           1.0   \n",
       "2                        0.0                           1.0   \n",
       "3                        0.0                           1.0   \n",
       "4                        0.0                           1.0   \n",
       "\n",
       "   VISITOR_TEAM_CONFERENCE_West  HOME_TEAM_WINS  \n",
       "0                           1.0               1  \n",
       "1                           0.0               1  \n",
       "2                           0.0               1  \n",
       "3                           0.0               1  \n",
       "4                           0.0               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizing and ohe the data\n",
    "categorical_columns = ['SEASON', 'HOME_TEAM_CONFERENCE', 'VISITOR_TEAM_CONFERENCE']\n",
    "numerical_columns = ['PTS_home', 'FG_PCT_home', 'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home', 'PTS_away', 'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away', 'REB_away', 'HOME_TEAM_W_PCT', 'VISITOR_TEAM_W_PCT']\n",
    "target = df.pop('HOME_TEAM_WINS')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "transformer = ColumnTransformer([('scaler', scaler, numerical_columns), ('ohe', ohe, categorical_columns)], remainder='passthrough')\n",
    "\n",
    "transformed_df = transformer.fit_transform(df)\n",
    "\n",
    "ohe_columns = transformer.named_transformers_['ohe'].get_feature_names_out(input_features=categorical_columns)\n",
    "all_columns = numerical_columns + list(ohe_columns)\n",
    "\n",
    "# Convert the numpy array to a DataFrame\n",
    "df_transformed = pd.DataFrame(transformed_df, columns=all_columns)\n",
    "\n",
    "# adding back the target variable to the dataset\n",
    "df_transformed['HOME_TEAM_WINS'] = target\n",
    "\n",
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HOME_TEAM_WINS                  1.000000\n",
       "FG_PCT_home                     0.431611\n",
       "HOME_TEAM_W_PCT                 0.396118\n",
       "PTS_home                        0.394714\n",
       "AST_home                        0.301019\n",
       "FG3_PCT_home                    0.300957\n",
       "REB_home                        0.245151\n",
       "FT_PCT_home                     0.092896\n",
       "HOME_TEAM_CONFERENCE_West       0.041981\n",
       "VISITOR_TEAM_CONFERENCE_East    0.035941\n",
       "SEASON_2012                     0.013025\n",
       "SEASON_2010                     0.012279\n",
       "Name: HOME_TEAM_WINS, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for correlation between the variables and the target variable\n",
    "df_transformed.corr()['HOME_TEAM_WINS'].sort_values(ascending=False)[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_transformed.drop('HOME_TEAM_WINS', axis=1), df_transformed['HOME_TEAM_WINS'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001757\n",
      "         Iterations 23\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         HOME_TEAM_WINS   No. Observations:                18669\n",
      "Model:                          Logit   Df Residuals:                    18633\n",
      "Method:                           MLE   Df Model:                           35\n",
      "Date:                Mon, 04 Dec 2023   Pseudo R-squ.:                  0.9974\n",
      "Time:                        16:25:44   Log-Likelihood:                -32.800\n",
      "converged:                       True   LL-Null:                       -12682.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "================================================================================================\n",
      "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "PTS_home                       312.3515     72.074      4.334      0.000     171.088     453.615\n",
      "FG_PCT_home                     -0.1941      1.165     -0.167      0.868      -2.477       2.089\n",
      "FT_PCT_home                     -1.4778      0.665     -2.221      0.026      -2.782      -0.174\n",
      "FG3_PCT_home                     1.9321      0.798      2.420      0.016       0.367       3.497\n",
      "AST_home                        -2.3218      0.838     -2.772      0.006      -3.963      -0.680\n",
      "REB_home                        -0.0395      0.961     -0.041      0.967      -1.924       1.845\n",
      "PTS_away                      -316.8355     72.919     -4.345      0.000    -459.755    -173.916\n",
      "FG_PCT_away                     -4.0924      1.818     -2.251      0.024      -7.656      -0.529\n",
      "FT_PCT_away                     -1.2735      0.808     -1.576      0.115      -2.857       0.310\n",
      "FG3_PCT_away                     4.2787      1.118      3.829      0.000       2.088       6.469\n",
      "AST_away                         0.9484      0.895      1.060      0.289      -0.805       2.702\n",
      "REB_away                        -1.2413      1.003     -1.238      0.216      -3.206       0.724\n",
      "HOME_TEAM_W_PCT                 10.9914      2.432      4.520      0.000       6.225      15.758\n",
      "VISITOR_TEAM_W_PCT               7.4595      1.990      3.749      0.000       3.560      11.359\n",
      "SEASON_2003                    -18.4320        nan        nan        nan         nan         nan\n",
      "SEASON_2004                      8.4259        nan        nan        nan         nan         nan\n",
      "SEASON_2005                      1.5629        nan        nan        nan         nan         nan\n",
      "SEASON_2006                      0.4926        nan        nan        nan         nan         nan\n",
      "SEASON_2007                      4.8484        nan        nan        nan         nan         nan\n",
      "SEASON_2008                      1.6049        nan        nan        nan         nan         nan\n",
      "SEASON_2009                      4.2572        nan        nan        nan         nan         nan\n",
      "SEASON_2010                      3.5393        nan        nan        nan         nan         nan\n",
      "SEASON_2011                      7.4693        nan        nan        nan         nan         nan\n",
      "SEASON_2012                      3.2013        nan        nan        nan         nan         nan\n",
      "SEASON_2013                      1.5116        nan        nan        nan         nan         nan\n",
      "SEASON_2014                      5.0483        nan        nan        nan         nan         nan\n",
      "SEASON_2015                      6.9282        nan        nan        nan         nan         nan\n",
      "SEASON_2016                     11.7724        nan        nan        nan         nan         nan\n",
      "SEASON_2017                      1.0616        nan        nan        nan         nan         nan\n",
      "SEASON_2018                      5.7733        nan        nan        nan         nan         nan\n",
      "SEASON_2019                      6.5542        nan        nan        nan         nan         nan\n",
      "SEASON_2020                      1.9269        nan        nan        nan         nan         nan\n",
      "SEASON_2021                      3.5445        nan        nan        nan         nan         nan\n",
      "SEASON_2022                      1.5489        nan        nan        nan         nan         nan\n",
      "HOME_TEAM_CONFERENCE_East       31.0783        nan        nan        nan         nan         nan\n",
      "HOME_TEAM_CONFERENCE_West       31.5614        nan        nan        nan         nan         nan\n",
      "VISITOR_TEAM_CONFERENCE_East    30.9559    1.4e+07    2.2e-06      1.000   -2.75e+07    2.75e+07\n",
      "VISITOR_TEAM_CONFERENCE_West    31.6838    1.4e+07   2.26e-06      1.000   -2.75e+07    2.75e+07\n",
      "================================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.99 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustafajawaid/Documents/Berkeley/data102-final-project/venv/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:2383: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/Users/mustafajawaid/Documents/Berkeley/data102-final-project/venv/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:2383: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    }
   ],
   "source": [
    "# now we fit a logistic regression frequentist GLM model\n",
    "frequentist_model = sm.Logit(y_train, X_train).fit()\n",
    "print(frequentist_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking out the variables that are not significant (high p-values) or null\n",
    "high_p_vals = frequentist_model.pvalues[(frequentist_model.pvalues > 0.05) | (frequentist_model.pvalues.isnull())].index\n",
    "low_p_df = df_transformed.drop(high_p_vals, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.099883\n",
      "         Iterations 11\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         HOME_TEAM_WINS   No. Observations:                18669\n",
      "Model:                          Logit   Df Residuals:                    18660\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 04 Dec 2023   Pseudo R-squ.:                  0.8530\n",
      "Time:                        16:29:52   Log-Likelihood:                -1864.7\n",
      "converged:                       True   LL-Null:                       -12682.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "PTS_home              11.4095      0.282     40.465      0.000      10.857      11.962\n",
      "FT_PCT_home           -0.0915      0.045     -2.030      0.042      -0.180      -0.003\n",
      "FG3_PCT_home           0.1048      0.046      2.271      0.023       0.014       0.195\n",
      "AST_home              -0.3739      0.054     -6.918      0.000      -0.480      -0.268\n",
      "PTS_away             -11.1389      0.281    -39.688      0.000     -11.689     -10.589\n",
      "FG_PCT_away           -0.2680      0.062     -4.312      0.000      -0.390      -0.146\n",
      "FG3_PCT_away          -0.0462      0.050     -0.928      0.353      -0.144       0.051\n",
      "HOME_TEAM_W_PCT        0.6707      0.046     14.520      0.000       0.580       0.761\n",
      "VISITOR_TEAM_W_PCT    -0.3339      0.045     -7.500      0.000      -0.421      -0.247\n",
      "======================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.43 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "# redoing the train test split and fitting the model again\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(low_p_df.drop('HOME_TEAM_WINS', axis=1), low_p_df['HOME_TEAM_WINS'], test_size=0.3, random_state=42)\n",
    "frequentist_model2 = sm.Logit(y_train_2, X_train_2).fit()\n",
    "print(frequentist_model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/mustafajawaid/Documents/Berkeley/data102-final-project/predictors.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mustafajawaid/Documents/Berkeley/data102-final-project/predictors.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m frequentist_model_3 \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39mGLM(y_train_2, X_train_2, family\u001b[39m=\u001b[39msm\u001b[39m.\u001b[39mfamilies\u001b[39m.\u001b[39mBinomial())\u001b[39m.\u001b[39mfit_regularized(alpha\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, L1_wt\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mustafajawaid/Documents/Berkeley/data102-final-project/predictors.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m frequentist_model_3\u001b[39m.\u001b[39;49msummary()\n",
      "File \u001b[0;32m~/Documents/Berkeley/data102-final-project/venv/lib/python3.11/site-packages/statsmodels/base/model.py:1194\u001b[0m, in \u001b[0;36mResults.summary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msummary\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1189\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[39m    Summary\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[39m    Not implemented\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frequentist_model_3 = sm.GLM(y_train_2, X_train_2, family=sm.families.Binomial()).fit_regularized(alpha=0.1, L1_wt=0.5)\n",
    "frequentist_model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the first model:  0.9985003749062734\n",
      "Accuracy of the second model:  0.9513871532116971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustafajawaid/Documents/Berkeley/data102-final-project/venv/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:2383: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the test set for both models\n",
    "y_pred = frequentist_model.predict(X_test)\n",
    "y_pred_2 = frequentist_model2.predict(X_test_2)\n",
    "\n",
    "# Calculating the accuracy of the predictions\n",
    "y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "y_pred_2 = [1 if x > 0.5 else 0 for x in y_pred_2]\n",
    "\n",
    "print(\"Accuracy of the first model: \", sum(y_pred == y_test)/len(y_test))\n",
    "print(\"Accuracy of the second model: \", sum(y_pred_2 == y_test_2)/len(y_test_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
